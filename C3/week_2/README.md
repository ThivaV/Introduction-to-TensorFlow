# Week 2

## Word Embeddings

* References:

    * [TensorFlow Word Embedding Projector](https://projector.tensorflow.org/)
    * Datasets:
        * [Large Movie Review Dataset](https://ai.stanford.edu/~amaas/data/sentiment/)

* What is word embedding ?
* `TensorFlow Data Services` or `TFTS` (for short) and that contains many data sets and lots of different categories.

    * `!pip install -q tensorflow-datasets`

    * TensorFlow Data Services 
    ![TensorFlow Data Services](/img/C3/C3_Week_2_TF_DataServices.png)

    * Large Movie Review Dataset (We will find here 50,000 movie reviews which are classified as positive of negative)  
    ![Large Movie Review Dataset](/img/C3/C3_Large_Dataset.png)

* How word embedding works ?
* Difference between `Flatten()` & `GlobalAveragePooling1D()` layers ?
* 